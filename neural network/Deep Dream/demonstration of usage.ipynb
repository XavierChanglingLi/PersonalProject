{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required library\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "# Automatically reload external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-legislature",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the picture for the deep dream\n",
    "img_filename = os.path.join('data', 'mountain_1x.png')\n",
    "img = plt.imread(img_filename)\n",
    "print(f'Image size is {img.shape}')\n",
    "plt.imshow(img)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer learning, loading in pre-trained VGG16 network\n",
    "input_nonbatch_shape = img.shape\n",
    "vgg = tf.keras.applications.VGG16(input_shape=input_nonbatch_shape, include_top = False, weights = 'imagenet')\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-motel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of VGG16 network layers whose activation we want to sample.\n",
    "all_layer_names = [layer.name for layer in vgg.layers]\n",
    "layers = [vgg.get_layer(name).output for name in all_layer_names]\n",
    "#here we select the maxpooling layers. You may also choose different layers\n",
    "selectedLayerNames=[]\n",
    "selectedLayerInds=[]\n",
    "for i in range(len(all_layer_names)):\n",
    "    if 'pool' in all_layer_names[i]:\n",
    "        selectedLayerNames.append(all_layer_names[i])\n",
    "        selectedLayerInds.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load our deep_dream model\n",
    "from deep_dream import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now deep dream with the selected layers\n",
    "tf_net = tf.keras.Model(inputs=layers[0], outputs=layers)\n",
    "tf_img = tf.Variable(img)\n",
    "dream = DeepDream(net=tf_net,selected_layer_inds=selectedLayerInds,all_layer_names=all_layer_names)\n",
    "dream_img = dream.gradient_ascent(img_tf, n_iter=20, step_sz=0.01, clip_low=0, clip_high=1, verbose=False)\n",
    "dream_img = dream.tf2array(dream_img)\n",
    "plt.imshow(dream_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-collector",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to refine the result, we can run it with multiple image scales\n",
    "tf_img = tf.Variable(img)\n",
    "dream = DeepDream(net=tf_net,selected_layer_inds=selectedLayerInds,all_layer_names=all_layer_names)\n",
    "dream_img = dream.gradient_ascent_multiscale(img_tf, n_iter=10, step_sz=0.01, clip_low=0, clip_high=1, verbose=False)\n",
    "dream_img = dream.tf2array(dream_img)\n",
    "plt.imshow(dream_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
